{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases desbalanceadas\n",
    "\n",
    "Conjunto de datos de entrenamiento con clases minoritarias, por lo que la información esta sesagada\n",
    "\n",
    "## Podemos resolver el problema de diferentes formas: \n",
    "\n",
    "**Ajuste de Parámetros del modelo:** Ajustar la métrica del modelo para equilibrar a la clase minoritaria, dando un peso diferente durante el entrenamiento.\n",
    "\n",
    "**Modificar el Dataset:**  Eliminar datos de la clase mayoritaria para reducirla.\n",
    "\n",
    "**Muestras artificiales:** Crear muestras sintéticas utilizando algoritmos que intentan seguir la tendencia del grupo minoritario. \n",
    "\n",
    "**Ensamble de métodos:** Entrenar diversos modelos y entre todos obtener el resultado final.\n",
    "\n",
    "\n",
    "https://www.aprendemachinelearning.com/clasificacion-con-datos-desbalanceados/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteca: imbalanced-learn\n",
    "\n",
    "https://pypi.org/project/imbalanced-learn/\n",
    "\n",
    "$ pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?select=creditcard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # Importamos la clase de Regresión Lineal de scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # error\n",
    "from sklearn.metrics import classification_report\n",
    "# conda install -c conda-forge imbalanced-learn\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = \"./datasets/\"\n",
    "filename = 'creditcard.csv'\n",
    "fullpath = os.path.join(mainpath, filename)\n",
    "dataset= pd.read_csv (fullpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar información del DataFrame\n",
    "def info(df):\n",
    "    display(df.head(10))\n",
    "    print()\n",
    "    print(df.info())\n",
    "    print()\n",
    "    print(df.describe())\n",
    "    print()\n",
    "    print('Duplicated: ',df.duplicated().sum())\n",
    "    print()\n",
    "    print('Null values %:')\n",
    "    print(100*df.isnull().sum()/len(df))\n",
    "\n",
    "info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eleminar duplicados\n",
    "\n",
    "dataset.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contar valores de la columna Class\n",
    "print(dataset['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "\n",
    "* 284807 entradas y 31 características 30 float y la categoría a predecir int\n",
    "* 1081 duplicados eliminados\n",
    "* No hay valores ausentes\n",
    "* Clase desbalanceadas: \n",
    "\n",
    "        0    283253\n",
    "        1       473\n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar características y separación en conjunto de entrenamiento y conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=['Class'])\n",
    "target = dataset['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, X_test, Y_train, Y_test):\n",
    "    clf_base = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\")\n",
    "    clf_base.fit(X_train, Y_train)\n",
    "    return clf_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, train_features, train_target, test_features, test_target):\n",
    "   \n",
    "    eval_stats = {}\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n",
    "    \n",
    "    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "        \n",
    "        eval_stats[type] = {}\n",
    "    \n",
    "        pred_target = model.predict(features)\n",
    "        pred_proba = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        # F1\n",
    "        f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n",
    "        \n",
    "        # ROC\n",
    "        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n",
    "        roc_auc = metrics.roc_auc_score(target, pred_proba)    \n",
    "        eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "        # PRC\n",
    "        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n",
    "        aps = metrics.average_precision_score(target, pred_proba)\n",
    "        eval_stats[type]['APS'] = aps\n",
    "        \n",
    "        if type == 'train':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'green'\n",
    "\n",
    "        # Valor F1\n",
    "        ax = axs[0]\n",
    "        max_f1_score_idx = np.argmax(f1_scores)\n",
    "        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('threshold')\n",
    "        ax.set_ylabel('F1')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'Valor F1') \n",
    "\n",
    "        # ROC\n",
    "        ax = axs[1]    \n",
    "        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'            \n",
    "            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend(loc='lower center')        \n",
    "        ax.set_title(f'Curva ROC')\n",
    "        \n",
    "        # PRC\n",
    "        ax = axs[2]\n",
    "        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('recall')\n",
    "        ax.set_ylabel('precision')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'PRC')   \n",
    "        \n",
    "        eval_stats[type]['Exactitud'] = metrics.accuracy_score(target, pred_target)\n",
    "        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n",
    "    \n",
    "    df_eval_stats = pd.DataFrame(eval_stats)\n",
    "    df_eval_stats = df_eval_stats.round(2)\n",
    "    df_eval_stats = df_eval_stats.reindex(index=('Exactitud', 'F1', 'APS', 'ROC AUC'))\n",
    "    \n",
    "    print(df_eval_stats)\n",
    "    \n",
    "    return eval_stats['train']['F1'], eval_stats['test']['F1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = run_model(X_train, X_test, y_train, y_test)\n",
    "train_f1, test_f1 = evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz de confusion\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion matrix', size = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "\n",
    "* La exactitud del modelo es muy alta (aproximadamente 99.99%), lo que indica que el modelo clasifica correctamente la mayoría de las observaciones.\n",
    "\n",
    "* La especificidad es muy alta (aproximadamente 99.99%), lo que significa que el modelo es muy bueno para identificar correctamente las clases negativas (True Negatives).\n",
    "Moderada Precisión:\n",
    "\n",
    "* La precisión es moderada (aproximadamente 87.1%), lo que indica que cuando el modelo predice una clase positiva, es correcto el 87.1% de las veces.\n",
    "\n",
    "* La sensibilidad es baja (aproximadamente 54.5%), lo que significa que el modelo no es muy bueno para identificar correctamente las clases positivas (True Positives). Esto puede ser un problema si la clase positiva es de particular interés.\n",
    "\n",
    "* El F1-Score es moderado (aproximadamente 67.1%), lo que refleja un equilibrio entre la precisión y la sensibilidad. Sin embargo, la baja sensibilidad afecta negativamente el F1-Score\n",
    "\n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar el desbalance con un peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos un parámetro adicional en el modelo de Regresión logística en donde indicamos weight = “balanced” y con esto el algoritmo se encargará de equilibrar a la clase minoritaria durante el entrenamiento donde el peso asignado es:\n",
    "\n",
    "\\begin{equation}\n",
    "w(j) = \\frac{n}{K * n(j)}\n",
    "\\end{equation}\n",
    "\n",
    "donde $n$ es el numero de datos, $K$ es el total de clases y $n(j)$ es el número de datos de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_balanced_1(X_train, X_test, Y_train, Y_test):\n",
    "    clf = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight=\"balanced\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_balanced = run_model_balanced_1(X_train, X_test, y_train, y_test)\n",
    "train_f1, test_f1 = evaluate_model(model_balanced, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "\n",
    "El F1-Score es muy bajo (0.12 en entrenamiento y 0.11 en prueba). Esto sugiere que el modelo tiene dificultades para identificar correctamente la clase minoritaria.\n",
    "\n",
    "Un F1-Score bajo indica que el modelo tiene un equilibrio pobre entre precisión y sensibilidad para la clase minoritaria.\n",
    "\n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['Class'].value_counts()/len(dataset)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_balanced_2(X_train, X_test, Y_train, Y_test):\n",
    "    clf = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight={0: 0.2,1: 0.8})\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced = run_model_balanced_2(X_train, X_test, y_train, y_test)\n",
    "train_f1, test_f1 = evaluate_model(model_balanced, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss \n",
    "\n",
    "Es un algoritmo que reduce la clase mayoritaria que utiliza un algoritmo similar al k-nearest neighbor para ir seleccionando cuales eliminar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = NearMiss()\n",
    "X_train_res, y_train_res = us.fit_resample(X_train, y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(y_train)))\n",
    "print (\"after resampling {}\".format(Counter(y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, y_train_res, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "train_f1, test_f1 = evaluate_model(model, X_train_res, y_train_res, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomOverSampler\n",
    "\n",
    "Crea una muestras nuevas “sintéticas” de la clase minoritaria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os =  RandomOverSampler()\n",
    "X_train_res, y_train_res = os.fit_resample(X_train, y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(y_train)))\n",
    "print (\"after resampling {}\".format(Counter(y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, y_train_res, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "train_f1, test_f1 = evaluate_model(model, X_train_res, y_train_res, X_test, y_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "SMOTE es un método de sobremuestreo que crea una muestras sintéticas (no duplicadas) de la clase minoritaria, hasta que sea igual a la clase mayoritaria. SMOTE hace esto seleccionando registros similares y alterando ese registro una columna a la vez aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_us = SMOTE()\n",
    "X_train_res, y_train_res = os_us.fit_resample(X_train, y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(y_train)))\n",
    "print (\"after resampling {}\".format(Counter(y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, y_train_res, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "train_f1, test_f1 = evaluate_model(model, X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTETomek\n",
    "\n",
    "Consiste en aplicar en simultáneo un algoritmo de subsampling y otro de oversampling: SMOTE para oversampling: busca puntos vecinos cercanos y agrega puntos “en linea recta” entre ellos y Tomek para undersampling que quita los de distinta clase que sean vecinos cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_us = SMOTETomek()\n",
    "X_train_res, y_train_res = os_us.fit_resample(X_train, y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(y_train)))\n",
    "print (\"after resampling {}\".format(Counter(y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, y_train_res, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "train_f1, test_f1 = evaluate_model(model, X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble de Modelos con Balanceo\n",
    "\n",
    "El ensamble de modelos es una técnica usada para reducir la varianza de las predicciones a través de la combinación de los resultados de varios clasificadores. Además de esto, se aborda el problema de los datos desequilibrados mediante el uso de submuestreo aleatorio para equilibrar la distribución de clases en cada subconjunto. Esto ayuda a reducir el sesgo hacia la clase mayoritaria y mejorar el desempeño de la clase minoritaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear el BalancedBaggingClassifier con el argumento correcto\n",
    "bbc = BalancedBaggingClassifier(estimator=RandomForestClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "\n",
    "bbc.fit(X_train, y_train)\n",
    "y_pred = bbc.predict(X_test)\n",
    "train_f1, test_f1 = evaluate_model(bbc, X_train, y_train, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
