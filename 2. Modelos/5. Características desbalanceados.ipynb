{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases desbalanceadas\n",
    "\n",
    "Conjunto de datos de entrenamiento con clases minoritarias, por lo que la información esta sesagada\n",
    "\n",
    "## Podemos resolver el problema de diferentes formas: \n",
    "\n",
    "**Ajuste de Parámetros del modelo:** Ajustar la métrica del modelo para equilibrar a la clase minoritaria, dando un peso diferente durante el entrenamiento.\n",
    "\n",
    "**Modificar el Dataset:**  Eliminar datos de la clase mayoritaria para reducirla.\n",
    "\n",
    "**Muestras artificiales:** Crear muestras sintéticas utilizando algoritmos que intentan seguir la tendencia del grupo minoritario. \n",
    "\n",
    "**Ensamble de métodos:** Entrenar diversos modelos y entre todos obtener el resultado final.\n",
    "\n",
    "\n",
    "https://www.aprendemachinelearning.com/clasificacion-con-datos-desbalanceados/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteca: imbalanced-learn\n",
    "\n",
    "https://pypi.org/project/imbalanced-learn/\n",
    "\n",
    "$ pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?select=creditcard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # Importamos la clase de Regresión Lineal de scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = \"../datasets/\"\n",
    "filename = 'creditcard.csv'\n",
    "fullpath = os.path.join(mainpath, filename)\n",
    "dataset= pd.read_csv (fullpath)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(dataset['Class'], sort = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset['Class']\n",
    "X = dataset.drop('Class', axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, X_test, Y_train, Y_test):\n",
    "    clf_base = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\")\n",
    "    clf_base.fit(X_train, Y_train)\n",
    "    return clf_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run_model(X_train, X_test, Y_train, Y_test)\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(Y_test, Y_pred):\n",
    "    conf_matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap = 'Blues_r')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "    print (classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar el desbalance con un peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos un parámetro adicional en el modelo de Regresión logística en donde indicamos weight = “balanced” y con esto el algoritmo se encargará de equilibrar a la clase minoritaria durante el entrenamiento donde el peso asignado es:\n",
    "\n",
    "\\begin{equation}\n",
    "w(j) = \\frac{n}{K * n(j)}\n",
    "\\end{equation}\n",
    "\n",
    "donde $n$ es el numero de datos, $K$ es el total de clases y $n(j)$ es el número de datos de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_balanced(X_train, X_test, Y_train, Y_test):\n",
    "   # clf = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight={0: 0.2,1: 0.8})\n",
    "    clf = LogisticRegression(C=1.0,penalty='l2',random_state=1,solver=\"newton-cg\",class_weight=\"balanced\")\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = run_model_balanced(X_train, X_test, Y_train, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss \n",
    "\n",
    "Es un algoritmo que reduce la clase mayoritaria que utiliza un algoritmo similar al k-nearest neighbor para ir seleccionando cuales eliminar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = NearMiss()\n",
    "X_train_res, Y_train_res = us.fit_resample(X_train, Y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(Y_train)))\n",
    "print (\"after resampling {}\".format(Counter(Y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, Y_train_res, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomOverSampler\n",
    "\n",
    "Crea una muestras nuevas “sintéticas” de la clase minoritaria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os =  RandomOverSampler()\n",
    "X_train_res, Y_train_res = os.fit_resample(X_train, Y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(Y_train)))\n",
    "print (\"after resampling {}\".format(Counter(Y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, Y_train_res, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "SMOTE es un método de sobremuestreo que crea una muestras sintéticas (no duplicadas) de la clase minoritaria. hasta que sea igual a la clase mayoritaria. SMOTE hace esto seleccionando registros similares y alterando ese registro una columna a la vez aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_us = SMOTE()\n",
    "X_train_res, Y_train_res = os_us.fit_resample(X_train, Y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(Y_train)))\n",
    "print (\"after resampling {}\".format(Counter(Y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, Y_train_res, Y_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTETomek\n",
    "\n",
    "Consiste en aplicar en simultáneo un algoritmo de subsampling y otro de oversampling: SMOTE para oversampling: busca puntos vecinos cercanos y agrega puntos “en linea recta” entre ellos y Tomek para undersampling que quita los de distinta clase que sean vecinos cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_us = SMOTETomek()\n",
    "X_train_res, Y_train_res = os_us.fit_resample(X_train, Y_train)\n",
    " \n",
    "print (\"before resampling {}\".format(Counter(Y_train)))\n",
    "print (\"after resampling {}\".format(Counter(Y_train_res)))\n",
    " \n",
    "model = run_model(X_train_res, X_test, Y_train_res, Y_test)\n",
    "pred_y = model.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble de Modelos con Balanceo\n",
    "\n",
    "El ensamble de modelos es una técnica usada para reducir la varianza de las predicciones a través de la combinación de los resultados de varios clasificadores. Además de esto, se aborda el problema de los datos desequilibrados mediante el uso de submuestreo aleatorio para equilibrar la distribución de clases en cada subconjunto. Esto ayuda a reducir el sesgo hacia la clase mayoritaria y mejorar el desempeño de la clase minoritaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    " \n",
    "bbc.fit(X_train, Y_train)\n",
    "Y_pred = bbc.predict(X_test)\n",
    "show_result(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
