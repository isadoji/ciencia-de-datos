{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de datos\n",
    "\n",
    "Es importante conocer con que tipos de datos estamos trabajando. Los datos pueden ser:\n",
    "\n",
    "1. Cuantitativos o numéricos (discretos y continuos)\n",
    "2. Cualitativos o categóricos\n",
    "3. Ordinales\n",
    "\n",
    "## Datos cuantitativos \n",
    "\n",
    "Son representados por números y son importantes si representan la medida de la cantidad observada \n",
    "de cierta característica. Pueden ser:\n",
    "\n",
    "1. Discretos: solo pueder asuamir un valor de una lista de números específicos, pueden ser contados y listados.\n",
    "\n",
    "2. Continuos: representan mediciones se suelen redondear a un número fijo de decimales para facilitar su manipulación.\n",
    "\n",
    "## Datos cualitativos\n",
    "\n",
    "Estos datos describen categorías no numéricas que representar determinada cualidad. Los datos categóricos pueden tomar valores numéricos (por ejemplo, \"0\" para indicar \"masculino\" y \"1\" para indicar \"femenino\"), pero esos números no tienen un sentido matemático.\n",
    "\n",
    "## Datos ordinales\n",
    "\n",
    " Es una categoría intermedia entre los cuantitativos y los cualitativos. En estos datos existe un orden (primero, segundo, tercero, etc.) es decir, podemos establecer un ranking, es decir, los datos son cualitativos, pero los números colocados en cada categoría tienen un significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = \"../datasets/\"\n",
    "filename = \"titanic-kaggle/train.csv\"\n",
    "fullpath = os.path.join(mainpath, filename)\n",
    "data = pd.read_csv (fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.drop(['Cabin','Name','Ticket'], axis=1)\n",
    "data1 = data1[data1['Embarked'].notna()]\n",
    "data1['Age'] = data1['Age'].fillna(-1)\n",
    "\n",
    "### Datos ordinales\n",
    "\n",
    "data1['Embarked'] = data1['Embarked'].map({'Q': 2, 'C': 1, 'S': 0})\n",
    "data1['Sex'] = data1['Sex'].map({'female': 1, 'male': 0})\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadistica basica de variables númericas \n",
    "data1.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Categorización de los datos en hombre/mujeres vivos/muertos\n",
    "\"\"\"\n",
    "live = data1[(data1[\"Survived\"]==1)]\n",
    "dead = data1[(data1[\"Survived\"]==0)]\n",
    "livem = data1[(data1[\"Survived\"]==1) & (data1[\"Sex\"] == 0)]\n",
    "livef = data1[(data1[\"Survived\"]==1) & (data1[\"Sex\"] == 1)]\n",
    "deadm = data1[(data1[\"Survived\"]==0) & (data1[\"Sex\"] == 0)]\n",
    "deadf = data1[(data1[\"Survived\"]==0) & (data1[\"Sex\"] == 1)]\n",
    "print(\"De los\",data1.shape[0], \"pasajeros del titanic\",\"sobrevivieron\",live.shape[0],\"y murieron\",dead.shape[0])\n",
    "print(\"De los\",live.shape[0], \"pasajeros que sobrevivieron\",livem.shape[0],\"eran hombres y\",livef.shape[0],\"eran mujeres\")\n",
    "print(\"De los\",dead.shape[0], \"pasajeros que murieron\",deadm.shape[0],\"eran hombres y\",deadf.shape[0],\"eran mujeres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfico de barras de frecuencias relativas.\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,4,1)\n",
    "plot = (100 * data1['Survived'].value_counts() / len(data1['Survived'])).plot(\n",
    "kind='pie',  autopct='%.2f',title='Sobrevivientes %')\n",
    "plt.subplot(1,4,2)\n",
    "plot = (100 * data1['Pclass'].value_counts() / len(data1['Pclass'])).plot(\n",
    "kind='pie' , autopct='%.2f', title='Pasajeros del Titanic %')\n",
    "plt.subplot(1,4,3)\n",
    "plot = (100 * data1['Sex'].value_counts() / len(data1['Sex'])).plot(\n",
    "kind='pie' , autopct='%.2f', title='Sexo de los Pasajeros del Titanic %')\n",
    "#plt.subplot(1,4,4)\n",
    "#plot = (100 * data1['Age'].value_counts() / len(data1['Age'])).plot(\n",
    "#kind='pie' , autopct='%.2f', title='Edad de los Pasajeros del Titanic %')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de atributos\n",
    "\n",
    "Proceso para seleccionar un subconjunto de atributos (columnas) relevantes para la construcción del modelo predictivo. Se utiliza para identificar y eliminar los atributos innecesarios, irrelevantes y/o redundantes que no contribuyen al modelo predictivo o disminuyen su precisión.\n",
    "\n",
    "Para hacer la selección de atributos, hay que tener en cuenta la relación que existe entre ellos  y así poder eliminarlos de forma individual (univariante) o un un grupo de atributos en forma conjunta (multivariante).\n",
    "\n",
    "Ejemplo: \n",
    "\n",
    "* **Modelo bayesiano**: cada atributo es independiente, por lo tanto, podemos hacer una selección de variable univariante.\n",
    "* **Modelo de red neuronal**: no asume la independencia de los atributos (usa todos los disponibles) por lo tanto, podemos hacer una selección de variable multivariante.\n",
    "\n",
    "## Métodos para selección de atributos\n",
    "\n",
    "1. **Métodos de filtrado**\n",
    "\n",
    "Aplican una medida estadística para asignar una puntuación a cada atributo. Los atributos luego son clasificados de acuerdo a su puntuación y son, o bien seleccionados para su conservación o eliminados del conjunto de datos. Los métodos de filtrado son a menudo univariantes y consideran a cada atributo en forma independiente, o con respecto a la variable dependiente.\n",
    "\n",
    "Ejemplos de estos métodos son: coeficientes de correlación de Pearson, prueba de $\\chi^2$, prueba de Fisher, ganancia de información.\n",
    "\n",
    "2. **Métodos empaquetados**\n",
    "\n",
    "Selección de un conjunto de atributos como un problema de búsqueda, en donde las diferentes combinaciones son evaluadas y comparadas. Para hacer estas evaluaciones se utiliza un modelo predictivo y luego se asigna una puntuación a cada combinación basada en la precisión del modelo.\n",
    "\n",
    "Ejemplo de este método es el algoritmo de eliminación recursiva (forward, backward) de atributos.\n",
    "\n",
    "Bibliografía:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feature_selection\n",
    "\n",
    "https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coeficientes de correlación de Pearson\n",
    "### \n",
    "def train_corr(data): \n",
    "    correlation = data.corr()\n",
    "    sns.heatmap(correlation, annot=True, cbar=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable numérica\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 5))\n",
    "axes = axes.flat\n",
    "columnas = data1.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas = columnas.drop('Survived') # objetivo\n",
    "\n",
    "for i, colum in enumerate(columnas):\n",
    "    sns.regplot(\n",
    "        x           = data1[colum],\n",
    "        y           = data1['Survived'],\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"Sobrevivientes vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "for i in [8]:\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlación con Sobrevivientes', fontsize = 10, fontweight = \"bold\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn feature selection\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest #SelectKBest removes all but the highest scoring features\n",
    "from sklearn.feature_selection import f_classif #Fisher\n",
    "from sklearn.feature_selection import RFE # recursive feature elimination\n",
    "from sklearn.ensemble import ExtraTreesClassifier #decision trees "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos las columnas objetivo\n",
    "\n",
    "* Objetivo: y\n",
    "* Atributos: x\n",
    "\n",
    "En este caso queremos saber quien sobrevivio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().any().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo va a aplicar la prueba de Fisher a todos los atributos y va a seleccionar los que mejor resultado obtuvieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data2['Survived']\n",
    "k = 4  # número de atributos a seleccionar\n",
    "entrenar = data2.drop(['Survived'], axis=1)\n",
    "columnas = list(entrenar.columns.values)\n",
    "seleccionadas = SelectKBest(f_classif, k=k).fit(entrenar, x)\n",
    "atrib = seleccionadas.get_support()\n",
    "atributos = [columnas[i] for i in list(atrib.nonzero()[0])]\n",
    "atributos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos empaquetados: Eliminación recursiva\n",
    "\n",
    "Selecciona recursivamente un número cada vez más pequeño de atributos. Primero comienza con todos los atributos del dataset y luego en cada pasada va eliminando aquellos que tenga el menor coeficiente de importancia hasta alcanzar el número de atributos deseado\n",
    "\n",
    "Es más precisa, pero consume mucho más recursos, ya que requiere entrenar un modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = ExtraTreesClassifier() \n",
    "erec = RFE(modelo)  \n",
    "erec = erec.fit(entrenar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrib = erec.support_\n",
    "atributos = [columnas[i] for i in list(atrib.nonzero()[0])]\n",
    "atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de atributos.\n",
    "modelo.fit(entrenar, x)\n",
    "modelo.feature_importances_[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(modelo.feature_importances_)[::-1][:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819112c24f0d6b36d35f6c5653e120a0c93a25f82bf2809eaf9b65613f02e80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
