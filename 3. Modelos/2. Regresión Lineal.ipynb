{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "Es un método estadístico que se utiliza para modelar la relación entre dos variables a travésde una línea recta. Esta línea recta se utiliza para predecir el valor de una variable desconocida, en función del valor de una variable conocida.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "                  Precio de la casa = b + m * tamaño de la casa\n",
    "\n",
    "Existen 2 tipos de regresión lineal:\n",
    "\n",
    "## Simple:\n",
    "\n",
    "Implica solo dos variables, una dependiente y una independiente. La variable independiente se utiliza para predecir la variable dependiente, mediante una línea recta.\n",
    "\n",
    "                y = β₀+β₁*x + ε\n",
    "\n",
    "donde:\n",
    "\n",
    "**y** es la variable independiente.\n",
    "\n",
    "**β** son dos constantes desconocidas que representan el punto de intersección (β₀) y la pendiente (β₁).\n",
    "\n",
    "**ε**  es la función de pérdida.\n",
    "\n",
    "## Múltiple\n",
    "\n",
    "Involucra mas variables independientes para predecir una variable dependiente. En este mopdelo, se ajusta una ecuación de regresión que explica la relación entre la variable dependiente y múltiples variables independientes.\n",
    "\n",
    "            y = β₀ + β₁x₁ + β₂x₂ +…+ βₐxₐ + ε \n",
    "            Y = β X (producto matricial)\n",
    "\n",
    "donde: \n",
    "\n",
    "**y** es la variable dependiente.\n",
    "\n",
    "**x** es una variable independiente.\n",
    "\n",
    "**β** son coeficientes.\n",
    "\n",
    "**ε** es la función de pérdida.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supuesto de linealidad\n",
    "\n",
    "**Linealidad**: La relación de las variables debe poder representarse con una línea recta.\n",
    "\n",
    "**Indepenencia**: El erro en una observación no debe estar relacionado con el error en otra observación.\n",
    "\n",
    "**Homocedasticidad**: Los errores deben tener varianzas iguales, es decir, la dispersión de los errores debe ser constante.\n",
    "\n",
    "**Normalidad**: Los errores deben seguir una distribución normal, es decir, la mayoría de los errores deben estar cerca de cero, así mismo su disprersión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de la regresión lineal\n",
    "\n",
    "Las técnicas comúnes para evaluar la regresión lineal, incluyen el error cuadrático medio, el coeficiente de determinación (R²), el análisis de residuos, la prueba de significancia y la validación cruzada. Estas técnicas pueden ayudar a determinar si el modelo de regresión lineal se ajusta bien a los datos y si se adecuado para su uso.\n",
    "\n",
    "**RMS**: El proceso de aprendizaje consiste en averiguar qué parámetros β minimizan el error cuadrático medio entre los resultados reales y los estimados.\n",
    "\n",
    "**R²**:  Para la regresión lineal simple, R² es simplemente el cuadrado del coeficiente de correlación de Pearson\n",
    "\n",
    "https://github.com/isadoji/FisComp/blob/main/3.3.Metodo%20de%20Minimos%20Cudrados.ipynb\n",
    "\n",
    "Es decir, la proporción que de la variabilidad de los datos de Y respecto a su media (denominador: variabilidad total) se atribuye a la regresión (numerador: variabilidad explicada). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Regresión Lineal Simple\n",
    "\n",
    "## Scikit learn: Linear Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):  # función f(x) = 2*x + 10 + 20*ruido\n",
    "    np.random.seed(42)\n",
    "    y = 2*x + 10 + 20*np.random.randn(x.shape[0])\n",
    "    return y\n",
    "x = np.arange(0, 200, 5) \n",
    "y = f(x) \n",
    "plt.scatter(x,y,label='data', color='blue')\n",
    "plt.title('Datos')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x) = 2*x + 10 + 0.2*ruido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # Importamos la clase de Regresión Lineal de scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # error\n",
    "regresion_lineal = LinearRegression() # crear lel objeto de Regresión Linear\n",
    "regresion_lineal.fit(x.reshape(-1,1), y) #Entrenamos nuestro modelo\n",
    "prediccion_entrenamiento = regresion_lineal.predict(x.reshape(-1,1)) #predicciones \n",
    "# Error Cuadrado Medio\n",
    "mse = mean_squared_error(y_true = y, y_pred = prediccion_entrenamiento)\n",
    "# La raíz cuadrada del MSE es el RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "# calculamos el coeficiente de determinación R2\n",
    "r2 = regresion_lineal.score(x.reshape(-1,1), y)\n",
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) # parámetros que ha estimado la regresión lineal\n",
    "print('Error Cuadrático Medio (MSE) = ' + str(mse) + ' , Raíz del Error Cuadrático Medio (RMSE) = ' + str(rmse) + ',Coeficiente de Determinación R2 = ' + str(r2))\n",
    "print('Coeficiente de Determinación R2 = ' + str(r2))\n",
    "plt.scatter(x, y, color=\"red\")\n",
    "plt.plot(x, prediccion_entrenamiento, color=\"blue\")\n",
    "plt.title('Datos')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Regresión Lineal con base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mainpath = \"../datasets/\"\n",
    "filename = 'salary_data.csv'\n",
    "fullpath = os.path.join(mainpath, filename)\n",
    "dataset= pd.read_csv (fullpath)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Independiente, tomara todos los valores menos la ultima\n",
    "x = dataset.iloc[:, :-1].values\n",
    "#Dependiente            \n",
    "y = dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de datos para entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear modelo de regresión lineal simple con el conjunto de entrenamiento\n",
    "\n",
    "#Ajustar el modelo usando el modelo de la clase (debe tener mismo numero de filas tanto x como y)\n",
    "regresion_lineal.fit(x_train, y_train)\n",
    "#Creando un vector de predicciones, se debe tomar solo los valores independientes\n",
    "y_pred = regresion_lineal.predict(x_test)\n",
    "\n",
    "# The coefficients\n",
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_train, y_train, color=\"red\",label='Sample data')\n",
    "plt.plot(x_train, regresion_lineal.predict(x_train), color=\"blue\",label='Regression model')\n",
    "plt.title(\"Sueldo en relación con los años del conjunto de entrenamiento\")\n",
    "plt.xlabel(\"Años de experiencia\")\n",
    "plt.ylabel(\"Salarios\")\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_test, y_test, color=\"red\")\n",
    "plt.plot(x_train, regresion_lineal.predict(x_train), color=\"blue\")\n",
    "plt.title(\"Sueldo en relación con los años del conjunto de test\")\n",
    "plt.xlabel(\"Años de experiencia\")\n",
    "plt.ylabel(\"Salarios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('../datasets/Salary_Data.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los datos\n",
    "import seaborn as sns  # Gráficos\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.pairplot(dataset, height=3,kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos.iloc[:,2:3]\n",
    "Y = datos.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regresion_lineal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> <img src=\"fig/LR.png\" alt=\"Drawing\" style=\"width: 1000px;\"/></div>\n",
    "\n",
    "https://aprendeia.com/ventajas-y-desventajas-de-los-algoritmos-de-clasificacion-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicación de la varianza\n",
    "# Creamos un vector con el porcentaje de influencia de la varianza \n",
    "# para las dos variables resultantes del conjunto de datos\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases desbalanceadas\n",
    "\n",
    "Conjunto de datos de entrenamiento con clases minoritarias, por lo que la información esta sesagada\n",
    "\n",
    "## Podemos resolver el problema de diferentes formas: \n",
    "\n",
    "**Ajuste de Parámetros del modelo:** Ajustar la métrica del modelo para equilibrar a la clase minoritaria, dando u peso diferente durante el entrenamiento.\n",
    "\n",
    "**Modificar el Dataset:**  Eliminar datos de la clase mayoritaria para reducirla.\n",
    "\n",
    "**Muestras artificiales:** Crear muestras sintéticas utilizando algoritmos que intentan seguir la tendencia del grupo minoritario. \n",
    "\n",
    "**Ensamble de métodos:** Entrenar diversos modelos y entre todos obtener el resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalado de variables\n",
    "#crear un escalador estandar    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Diciendole entre que valores debe escalar\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "#Escalando el test y no se debe volver a crear un escalador (sc_x)\n",
    "#Y solo le diremos transform para que escale con el test \n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
