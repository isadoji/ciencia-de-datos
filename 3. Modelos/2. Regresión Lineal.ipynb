{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "Es un método estadístico que se utiliza para modelar la relación entre dos variables a travésde una línea recta. Esta línea recta se utiliza para predecir el valor de una variable desconocida, en función del valor de una variable conocida.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "                  Precio de la casa = b + m * tamaño de la casa\n",
    "\n",
    "Existen 2 tipos de regresión lineal:\n",
    "\n",
    "## Simple:\n",
    "\n",
    "Implica solo dos variables, una dependiente y una independiente. La variable independiente se utiliza para predecir la variable dependiente, mediante una línea recta.\n",
    "\n",
    "                y = β₀+β₁*x + ε\n",
    "\n",
    "donde:\n",
    "\n",
    "**y** es la variable independiente.\n",
    "\n",
    "**β** son dos constantes desconocidas que representan el punto de intersección (β₀) y la pendiente (β₁).\n",
    "\n",
    "**ε**  es la función de pérdida.\n",
    "\n",
    "## Múltiple\n",
    "\n",
    "Involucra mas variables independientes para predecir una variable dependiente. En este mopdelo, se ajusta una ecuación de regresión que explica la relación entre la variable dependiente y múltiples variables independientes.\n",
    "\n",
    "            y = β₀ + β₁x₁ + β₂x₂ +…+ βₐxₐ + ε \n",
    "            Y = β X (producto matricial)\n",
    "\n",
    "donde: \n",
    "\n",
    "**y** es la variable dependiente.\n",
    "\n",
    "**x** es una variable independiente.\n",
    "\n",
    "**β** son coeficientes.\n",
    "\n",
    "**ε** es la función de pérdida.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supuesto de linealidad\n",
    "\n",
    "**Linealidad**: La relación de las variables debe poder representarse con una línea recta.\n",
    "\n",
    "**Indepenencia**: El erro en una observación no debe estar relacionado con el error en otra observación.\n",
    "\n",
    "**Homocedasticidad**: Los errores deben tener varianzas iguales, es decir, la dispersión de los errores debe ser constante.\n",
    "\n",
    "**Normalidad**: Los errores deben seguir una distribución normal, es decir, la mayoría de los errores deben estar cerca de cero, así mismo su disprersión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de la regresión lineal\n",
    "\n",
    "Las técnicas comúnes para evaluar la regresión lineal, incluyen el error cuadrático medio, el coeficiente de determinación (R²), el análisis de residuos, la prueba de significancia y la validación cruzada. Estas técnicas pueden ayudar a determinar si el modelo de regresión lineal se ajusta bien a los datos y si se adecuado para su uso.\n",
    "\n",
    "**RMS**: El proceso de aprendizaje consiste en averiguar qué parámetros β minimizan el error cuadrático medio entre los resultados reales y los estimados.\n",
    "\n",
    "**R²**:  Para la regresión lineal simple, R² es simplemente el cuadrado del coeficiente de correlación de Pearson\n",
    "\n",
    "https://github.com/isadoji/FisComp/blob/main/3.3.Metodo%20de%20Minimos%20Cudrados.ipynb\n",
    "\n",
    "Es decir, la proporción que de la variabilidad de los datos de Y respecto a su media (denominador: variabilidad total) se atribuye a la regresión (numerador: variabilidad explicada). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Regresión Lineal Simple\n",
    "\n",
    "## Scikit learn: Linear Regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):  # función f(x) = 2*x + 10 + 20*ruido\n",
    "    np.random.seed(42)\n",
    "    y = 2*x + 10 + 20*np.random.randn(x.shape[0])\n",
    "    return y\n",
    "x = np.arange(0, 200, 5) \n",
    "y = f(x) \n",
    "plt.scatter(x,y,label='data', color='blue')\n",
    "plt.title('Datos')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x) = 2*x + 10 + 0.2*ruido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # Importamos la clase de Regresión Lineal de scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # error\n",
    "regresion_lineal = LinearRegression() # crear lel objeto de Regresión Linear\n",
    "regresion_lineal.fit(x.reshape(-1,1), y) #Entrenamos nuestro modelo\n",
    "prediccion_entrenamiento = regresion_lineal.predict(x.reshape(-1,1)) #predicciones \n",
    "# Error Cuadrado Medio\n",
    "mse = mean_squared_error(y_true = y, y_pred = prediccion_entrenamiento)\n",
    "# La raíz cuadrada del MSE es el RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "# calculamos el coeficiente de determinación R2\n",
    "r2 = regresion_lineal.score(x.reshape(-1,1), y)\n",
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) # parámetros que ha estimado la regresión lineal\n",
    "print('Error Cuadrático Medio (MSE) = ' + str(mse) + ' , Raíz del Error Cuadrático Medio (RMSE) = ' + str(rmse) + ',Coeficiente de Determinación R2 = ' + str(r2))\n",
    "print('Coeficiente de Determinación R2 = ' + str(r2))\n",
    "plt.scatter(x, y, color=\"red\")\n",
    "plt.plot(x, prediccion_entrenamiento, color=\"blue\")\n",
    "plt.title('Datos')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Regresión Lineal con base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('../datasets/salary_data.csv')\n",
    "#Independiente, tomara todos los valores menos la ultima\n",
    "x = dataset.iloc[:, :-1].values\n",
    "#Dependiente            \n",
    "y = dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de datos para entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear modelo de regresión lineal simple con el conjunto de entrenamiento\n",
    "\n",
    "#Ajustar el modelo usando el modelo de la clase (debe tener mismo numero de filas tanto x como y)\n",
    "regresion_lineal.fit(x_train, y_train)\n",
    "#Creando un vector de predicciones, se debe tomar solo los valores independientes\n",
    "y_pred = regresion_lineal.predict(x_test)\n",
    "\n",
    "# The coefficients\n",
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_train, y_train, color=\"red\",label='Sample data')\n",
    "plt.plot(x_train, regresion_lineal.predict(x_train), color=\"blue\",label='Regression model')\n",
    "plt.title(\"Sueldo en relación con los años del conjunto de entrenamiento\")\n",
    "plt.xlabel(\"Años de experiencia\")\n",
    "plt.ylabel(\"Salarios\")\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_test, y_test, color=\"red\")\n",
    "plt.plot(x_train, regresion_lineal.predict(x_train), color=\"blue\")\n",
    "plt.title(\"Sueldo en relación con los años del conjunto de test\")\n",
    "plt.xlabel(\"Años de experiencia\")\n",
    "plt.ylabel(\"Salarios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/isadoji/Storage/github/ciencia-de-datos/3. Modelos/2. Regresión Lineal.ipynb Cell 13\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/isadoji/Storage/github/ciencia-de-datos/3.%20Modelos/2.%20Regresi%C3%B3n%20Lineal.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/isadoji/Storage/github/ciencia-de-datos/3.%20Modelos/2.%20Regresi%C3%B3n%20Lineal.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cm \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mconfusion_matrix(y_test, y_pred)\n",
      "File \u001b[0;32m~/Storage/Software/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m     \u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/Storage/Software/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('../datasets/Salary_Data.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los datos\n",
    "import seaborn as sns  # Gráficos\n",
    "\n",
    "sns.set_palette('colorblind')\n",
    "sns.pairplot(datos, height=3,kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos.iloc[:,2:3]\n",
    "Y = datos.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_lineal.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('m = ' + str(regresion_lineal.coef_) + ', b = ' + str(regresion_lineal.intercept_)) \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> <img src=\"fig/LR.png\" alt=\"Drawing\" style=\"width: 1000px;\"/></div>\n",
    "\n",
    "https://aprendeia.com/ventajas-y-desventajas-de-los-algoritmos-de-clasificacion-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Escalado de variables\n",
    "#crear un escalador estandar    \n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Diciendole entre que valores debe escalar\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "#Escalando el test y no se debe volver a crear un escalador (sc_x)\n",
    "#Y solo le diremos transform para que escale con el test \n",
    "x_test = sc_x.transform(x_test)\n",
    "'''\n",
    "#--------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
